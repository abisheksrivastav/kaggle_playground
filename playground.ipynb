{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import scipy.optimize as optimize\n",
    "import scipy.integrate as integrate\n",
    "import scipy.special as special"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import MaxNLocator, FormatStrFormatter, PercentFormatter\n",
    "from datetime import datetime, date, timedelta\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.linear_model import LinearRegression, HuberRegressor, Ridge, Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"C:\\\\Users\\\\user\\\\kaggle_playground\\\\data\\\\train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"C:\\\\Users\\\\user\\\\kaggle_playground\\\\data\\\\test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"C:\\\\Users\\\\user\\\\kaggle_playground\\\\data\\\\sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train data shape:  (26298, 6)\n",
      " Test data shape:  (6570, 5)\n",
      " Sample submission data shape:  (6570, 2)\n",
      "train_data\n",
      "    row_id        date  country       store         product  num_sold\n",
      "0       0  2015-01-01  Finland  KaggleMart      Kaggle Mug       329\n",
      "1       1  2015-01-01  Finland  KaggleMart      Kaggle Hat       520\n",
      "2       2  2015-01-01  Finland  KaggleMart  Kaggle Sticker       146\n",
      "3       3  2015-01-01  Finland  KaggleRama      Kaggle Mug       572\n",
      "4       4  2015-01-01  Finland  KaggleRama      Kaggle Hat       911\n",
      "test_data\n",
      "    row_id        date  country       store         product\n",
      "0   26298  2019-01-01  Finland  KaggleMart      Kaggle Mug\n",
      "1   26299  2019-01-01  Finland  KaggleMart      Kaggle Hat\n",
      "2   26300  2019-01-01  Finland  KaggleMart  Kaggle Sticker\n",
      "3   26301  2019-01-01  Finland  KaggleRama      Kaggle Mug\n",
      "4   26302  2019-01-01  Finland  KaggleRama      Kaggle Hat\n",
      "sample_submission\n",
      "    row_id  num_sold\n",
      "0   26298       100\n",
      "1   26299       100\n",
      "2   26300       100\n",
      "3   26301       100\n",
      "4   26302       100\n"
     ]
    }
   ],
   "source": [
    "print(\" Train data shape: \", train_data.shape)\n",
    "print(\" Test data shape: \", test_data.shape)\n",
    "print(\" Sample submission data shape: \", sample_submission.shape)\n",
    "print(\"train_data\\n\", train_data.head())\n",
    "print(\"test_data\\n\", test_data.head())\n",
    "print(\"sample_submission\\n\", sample_submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data null values\n",
      " row_id      0\n",
      "date        0\n",
      "country     0\n",
      "store       0\n",
      "product     0\n",
      "num_sold    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# null values\n",
    "print(\"train_data null values\\n\", train_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26298 entries, 0 to 26297\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   row_id    26298 non-null  int64 \n",
      " 1   date      26298 non-null  object\n",
      " 2   country   26298 non-null  object\n",
      " 3   store     26298 non-null  object\n",
      " 4   product   26298 non-null  object\n",
      " 5   num_sold  26298 non-null  int64 \n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6570 entries, 0 to 6569\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   row_id   6570 non-null   int64 \n",
      " 1   date     6570 non-null   object\n",
      " 2   country  6570 non-null   object\n",
      " 3   store    6570 non-null   object\n",
      " 4   product  6570 non-null   object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 256.8+ KB\n"
     ]
    }
   ],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_month(date):\n",
    "      return date.split('-')[1]\n",
    "\n",
    "#Day\n",
    "def split_day(date):\n",
    "  return date.split('-')[2]\n",
    "\n",
    "#Weekend\n",
    "def weekend(date):\n",
    "  import datetime\n",
    "  weekend = []\n",
    "  a = pd.to_datetime(date)\n",
    "  for i in range(len(a)):\n",
    "    if a.iloc[i].weekday() >= 5 :\n",
    "      weekend.append(1)\n",
    "    else:\n",
    "      weekend.append(0)\n",
    "  return weekend\n",
    "\n",
    "#Weekday\n",
    "def weekday(date):\n",
    "    import datetime\n",
    "    weekday = []\n",
    "    a = pd.to_datetime(date)\n",
    "    for i in range(len(a)):\n",
    "        weekday.append(a.iloc[i].weekday())\n",
    "    return weekday\n",
    "train_data['Month'] = train_data['date'].apply(split_month)\n",
    "train_data['Day'] = train_data['date'].apply(split_day)\n",
    "train_data['Weekend'] = weekend(train_data['date'])\n",
    "train_data['Weekday'] = weekday(train_data['date'])\n",
    "train_data = train_data.drop(columns = ['row_id', 'date'])\n",
    "\n",
    "test_data['Month'] = test_data['date'].apply(split_month)\n",
    "test_data['Day'] = test_data['date'].apply(split_day)\n",
    "test_data['Weekend'] = weekend(test_data['date'])\n",
    "test_data['Weekday'] = weekday(test_data['date'])\n",
    "test_data = test_data.drop(columns = ['row_id', 'date'])\n",
    "#Dummies the 'country', 'store', 'product'\n",
    "train_data_dum = pd.get_dummies(train_data[['country', 'store', 'product']])\n",
    "test_data_dum = pd.get_dummies(test_data[['country', 'store', 'product']])\n",
    "\n",
    "train_data = pd.concat([train_data, train_data_dum],axis = 1)\n",
    "test_data = pd.concat([test_data, test_data_dum],axis = 1)\n",
    "\n",
    "train_data = train_data.drop(columns = ['country', 'store', 'product'])\n",
    "test_data = test_data.drop(columns = ['country', 'store', 'product'])\n",
    "\n",
    "data = train_data.drop(columns = 'num_sold')\n",
    "target = train_data['num_sold']\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "Normalize = StandardScaler()\n",
    "target = np.log(target)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, target, train_size = 0.8, random_state = 5)\n",
    "x_train = Normalize.fit_transform(x_train)\n",
    "x_test = Normalize.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBR = GradientBoostingRegressor(learning_rate=0.10, max_depth= 6,\n",
    "                                min_samples_leaf = 5,n_estimators = 500, random_state = 40,subsample = 0.3).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_GBR = GBR.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = GBR.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = Normalize.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_target= np.exp(GBR.predict(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['num_sold'] = submission_target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv('submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bc5325771484cd741460cbbcf20a153b1ef45b389ce85e60a186ce6bd8aea41f"
  },
  "kernelspec": {
   "display_name": "Python 3.6.3rc1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
